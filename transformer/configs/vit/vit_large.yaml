arch: 'vit'
model:
  micro_batch_size: 4
  global_batch_size: 128
  d_model: 1024
  depth: 24
  heads: 16
  mlp_dim: 4096
  dim_head: 64
  patch_size: 16
  normalized_shape: 1024
  image_size: 224
  num_classes: 1000
  decoder_layers: 0
  post_layernorm_residual: True
  dtype: fp16
  compute_dtype: fp16
  layernorm_dtype: fp32
  softmax_dtype: fp32
  hidden_act: gelu
  network_dropout_prob: 0.1
  feedforward_dropout_prob: 0.1
  attention_dropout_prob: 0.1

seed: 1234
context:
  device_target: 'GPU'
  device_id: 0
  save_graphs: True
  save_graphs_path: './model_ms'
  mode: 0
  enable_graph_kernel: False
  graph_kernel_flags: "--disable_cluster_ops=ReduceMax --disable_expand_ops=SoftmaxCrossEntropyWithLogits,Softmax,LogSoftmax"

recompute_config:
  recompute: False
  parallel_optimizer_comm_recompute: False
  mp_comm_recompute: True
  recompute_slice_activation: False

parallel_mode: "semi_auto_parallel"

parallel_config:
  data_parallel: 1
  model_parallel: 1
  expert_parallel: 1
  pipeline_stage: 1
  optimizer_shard: False

moe_config:
  expert_num: 1
  capacity_factor: 1.1
  aux_loss_factor: 0.05
  num_experts_chosen: 1

speed_up:
  micro_batch_num: 1
  flatten_weights: False
  fused_kernel: False

acc_step: 1
full_batch: False

# dataset
dataset_name: imagenet
data_url: '/ms_test1/mindspore_dataset/ImageNet2012/train/'
eval_data_path: '/ms_test1/mindspore_dataset/ImageNet2012/validation_preprocess/'
split_point: 0.4
poly_power: 2
aux_factor: 0.4
interpolation: 'BILINEAR'
crop_min: 0.05
train_num_workers: 12

# lr
lr_decay_mode: 'cosine'
lr_init: 0.0
lr_max: 0.00355
lr_min: 0.0
epoch_size: 300
warmup_epochs: 40

# optimizer
optimizer: 'adamw'
beta1: 0.9
beta2: 0.999
weight_decay: 0.05
no_weight_decay_filter: "beta,bias"
gc_flag: 0
opt_offload: False

# loss
loss_scale: 1024
use_label_smooth: 1
label_smooth_factor: 0.1
mixup: 0.2
autoaugment: 1
loss_name: "ce_smooth_mixup"
init_loss_scale_value: 65536
scale_factor: 2
scale_window: 1000


grad_sync_dtype: fp16
sink_size: 50
ckpt_save_dir: ./ckpt

# eval: True
# ckpt_path: /home/jenkins/shiwenqi/transformer/ckpt./ckpt_6/vit_3-120_625.ckpt
eval: False
load_checkpoint_path: None
eval_batch_size: 128
eval_interval: 1
eval_offset: -1
eval_num_workers: 12
generate: False