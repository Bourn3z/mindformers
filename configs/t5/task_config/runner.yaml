# runner config
runner_config:
  epochs: 1
  batch_size: 1
  sink_mode: True
  per_epoch_size: -1
  initial_epoch: 0
  has_trained_epoches: 0
  has_trained_steps: 0

runner_wrapper:
  type: TrainOneStepWithClipGN
  scale_sense:
    type: DynamicLossScaleUpdateCell
    scale_factor: 2
    scale_window: 1000
    loss_scale_value: 65536
  use_clip_grad: True
  clip_norm: 1.0

# optimizer
optimizer:
  type: AdamWeightDecay
  beta1: 0.9
  beta2: 0.999
  eps: 0.00000001 # 1e-8
  weight_decay: 0.00

# lr sechdule
lr_schedule:
  type: WarmUpDecayLR
  learning_rate: 0.00005
  end_learning_rate: 0.0
  warmup_steps: 0
  decay_steps: -1 # -1 means it will laod the total steps of the dataset

callbacks:
  - type: LossMonitor
  - type: CheckpointMointor
    prefix: "mindformers"
    save_checkpoint_steps: 1000
    integrated_save: True
    async_save: False
  - type: ObsMonitor