train_dataset: &train_dataset
  data_loader:
    type: MindDataset
    dataset_dir: ""
    shuffle: True
  tokenizer:
    type: GPT2Tokenizer
    max_length: 1025
  input_columns: ["input_ids"]
  num_parallel_workers: 8
  python_multiprocessing: False
  drop_remainder: True
  batch_size: 8
  repeat: 1
  numa_enable: False
  prefetch_size: 1

train_dataset_task:
  type: CausalLanguageModelDataset
  dataset_config: *train_dataset

eval_dataset: &eval_dataset
  data_loader:
    type: MindDataset
    dataset_dir: ""
    shuffle: False
  tokenizer:
    type: GPT2Tokenizer
    max_length: 1024
  input_columns: ["input_ids"]
  num_parallel_workers: 8
  python_multiprocessing: False
  drop_remainder: False
  batch_size: 1
  repeat: 1
  numa_enable: False
  prefetch_size: 1

eval_dataset_task:
  type: CausalLanguageModelDataset
  dataset_config: *eval_dataset
