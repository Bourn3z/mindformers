model:
  arch:
    type: ClipModel

  model_config:
    type: ClipConfig

    text_config:
      type: ClipTextConfig
      hidden_size: 512
      vocab_size: 49408
      max_position_embeddings: 77
      num_hidden_layers: 12

    vision_config:
      type: ClipVisionConfig
      hidden_size: 768
      image_size: 224
      patch_size: 32
      num_hidden_layers: 12

    projection_dim: 512
    ratio: 64

processor:
  type: ClipProcessor

  feature_extractor:
    type: ClipFeatureExtractor

    image_feature_extractor:
      type: ClipImageFeatureExtractor

      image_resolution: 224

  tokenizer:
    type: ClipTokenizer